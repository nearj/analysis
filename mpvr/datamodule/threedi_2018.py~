import numpy as np
import pandas as pd
import cv2
from numba import jit

def load_motion_gen(path, axes, sensored_axes_tag, target_sampling_rate, indices, timediffs):
    df = pd.read_csv(self.setting.motion_data.path, encoding="ISO-8859-1")
    for it in list(zip(*indices, timediffs)):
        ret = []
        for ax in axes:
            if ax in sensored_axes_tag.keys():
                ret.append(df[sensored_axes_tag[ax]][it[0]] / it[1] / target_sampling_rate)
            else:
                ret.append(0)
        yield np.array(ret)

def load_visual_gen(path, target_sampling_rate, extension, timediffs, indices):
    src = _visual_src_maker(path, indices, extension)
    prev = next(src)
    for t in timediffs[1:]:
        cur = next(src)
        flow = cv2.calcOpticalFlowFarneback(prev, cur, None, 0.5, 4, 15, 3, 5, 1.2, 0)
        polars = np.asarray(cv2.cartToPolar(flow[...,0], flow[...,1], None, None, True))
        polars = polars.reshape(2, polars.shape[1] * polars.shape[2]).T / timediffs[j] \
            / target_sampling_rate
        prev = cur
        yield polars

def _visual_src_maker(path, indices, extension):
    if extension == '.mp4':
        cap = cv2.VideoCapture(path)
        for i in indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, indices[i])
            yield cv2.cvtColor(cap.read()[1], cv2.COLOR_BGR2GRAY)
        cap.release()

    elif extension == '.png':
        for i in indices:
            yield cv2.cvtColor(cv2.imread(path + "{:0>4d}.png".format(indices[i])),
                               cv2.COLOR_BGR2GRAY)

def classification_motion(motion_vector, seperator = None):
    max_values = np.max(np.abs([mv for mv in motion_vector]), axis = 0)
    bins = np.array([np.array(setting.motion_data.motion_seperator) * m for m in max_values])
    return _classification_motion_helper(motion_vector, bins)

def classification_visual(polars):
    return np.array([_classification_video_helper(polar[0], polar[1]) for polar in polars])

@jit(nopython = True)
def _classification_motion_helper(motion_vector, bins):
    modifier = 1
    ret = 0
    for i in range(len(motion_vector)):
        for j in range(len(bins[i])):
            if motion_vector[i] < bins[i][j]:
                ret += (j-2) * modifier
                break
            elif motion_vector[i] >= bins[i][-1]:
                ret += (j-1) * modifier
        modifier *= 5
    return np.array(ret)

@jit(nopython = True)
def _classification_video_helper(mag, deg):
    tmp = 0
    if deg < 195:
        if deg < 105:
            if deg < 45:
                if deg > 15:
                    tmp = 1
            else:
                if deg < 75:
                    tmp = 2
                else:
                    tmp = 3
        else:
            if deg < 165:
                if deg < 135:
                    tmp = 4
                else:
                    tmp = 5
            else:
                tmp = 6
    else:
        if deg < 315:
            if deg < 255:
                if deg < 225:
                    tmp = 7
                else:
                    tmp = 8
            else:
                if deg < 285:
                    tmp = 9
                else:
                    tmp = 10
        else:
            if deg < 345:
                tmp = 11

    if mag < 20:
        if mag > 6:
            tmp += 12
    else:
        tmp += 24
    return tmp

    # def _load_with_preset(self):
    #     """Implementation method of :meth:'mpvr.datamanager.Datamanager.load()'

    #     :returns: Generator of classified motion and video process in experiment
    #     :rtype: Iterator[(int, list)]
    #     """
    #     motion_load_directory = _load_motion_dir + _scenario + _extension['csv']
    #     video_load_directory = _load_video_dir + _scenario + '/'

    #     df = pd.read_csv(motion_load_directory)

    #     times = pd.to_datetime(df[_time_column].str.split().str[1]).astype(int) / 10 ** 9
    #     times -= times[_start_index] # to set timestamps 0 at start index
    #     sampled_indices, sampled_deltatimes = _sampling_time(times)
    #     # to make sampling rate approximately about 3hz as previous works

    #     sensored_motion_vectors = np.diff(df[_sensored.values()].values, axis = 0)
    #     # order: pitch, yaw, roll
    #     motion_vectors = np.hstack((
    #         sensored_motion_vectors, np.zeros((
    #             sensored_motion_vectors.shape[0], len(_unsensored)))))
    #     # to make 6 axis motion, e.g.) (1.1, 2.2, 3.3) > (1.1, 2.2, 3.3, 0, 0, 0)

    #     sampled_motion = _sampling_motion(sampled_deltatimes,
    #                                             sampled_indices,
    #                                             motion_vectors)
    #     sampled_video = _load_visual_gen_from_png(sampled_deltatimes,
    #                                           sampled_indices,
    #                                           video_load_directory)
    #     motion_bins = _make_motion_bins(sampled_motion)

    #     # TODO: stands for rewind... >
    #     sampled_motion = _sampling_motion(sampled_deltatimes,
    #                                             sampled_indices,
    #                                             motion_vectors)

    #     for sample in zip(*(sampled_motion, sampled_video)):
    #         yield classification_motion(sample[0], motion_bins), \
    #             classification_visual(sample[1])

# def load_visual_gen(path, indices):
#     cap = cv2.VideoCapture(path)
#     i = 0
#     while i < indices[0]:
#         cap.read()

#     frame_max = cap.get(cv2.CAP_PROP_FRAME_COUNT)
#     while i <= frame_max:
#         if i in indices:
#             yield cv2.cvtColor(cap.read()[1], cv2.COLOR_BGR2GRAY)
#         else:
#             cap.read()
#         i += 1
#     cap.release()
# def _load_visual_gen_from_png(path, target_sampling_rate, timediffs, indices):
#     prev =
#     for x in list(zip(indices[1:], timediffs)):
#         cur = cv2.cvtColor(cv2.imread(load_dir +
#                                       "{:0>4d}.png".format(x[0])), cv2.COLOR_BGR2GRAY)
#         flow = cv2.calcOpticalFlowFarneback(prev, cur, None, 0.5, 4, 15, 3, 5, 1.2, 0)
#         polars = np.asarray(cv2.cartToPolar(flow[...,0], flow[...,1], None, None, True))
#         polars = polars.reshape(2, polars.shape[1] * polars.shape[2]).T / x[1] / 3
#         # to make approximately 3hz
#         prev = cur
#         yield polars
